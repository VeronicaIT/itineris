---
title: "<b>Plan de Gestion des données</b><br> du projet ANR <b>Itineris</b><br>"
bibliography: "D:/DocumentationArcheo/biblio12.bib"
# bibliography: "C:/Users/supernova/Dropbox/My PC (supernova-pc)/Documents/golasecca/bibliographie.bib"
# author: "Thomas Huet"
# runtime: shiny
output: 
  html_document:
    highlight: tango
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
---

```{r, echo=FALSE}
url.root <- "https://raw.githubusercontent.com/zoometh/itineris/main/www/"
htmltools::img(src = paste0(url.root, "logo.png"), 
               alt = 'logo', 
               width = '250px',
               style = 'position:absolute; top:0; right:0; padding:10px;')
```


<style>
.html-widget {
margin: auto;
}
</style>

```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = FALSE, fig.width = 19, fig.height = 14)
library(kableExtra) 
library(dplyr)
library(knitr)
library(shiny)
library(visNetwork)
library(stringi)
library(stringr)
library(rdflib)
library(openxlsx)
library(rgdal)
library(rgeos)
library(dismo)
library(deldir)
library(sp)
library(maptools)
library(sf)
library(raster)
library(leaflet)

text.size <- 15

# informations résumé
data.base <- 'https://raw.github.com/zoometh/itineris/master/data/'
url.data.res <- paste0(data.base, 'data_resume.tsv')
url.tools.res <- paste0(data.base, 'tools_resume.tsv')
url.isos.res <- paste0(data.base, 'isos_resume.tsv')
url.mbr_nodes.res <- paste0(data.base, 'mbr_nodes_resume.tsv')
url.mbr_edges.res <- paste0(data.base, 'mbr_edges_resume.tsv')


data.res <- read.table(url.data.res, header = T, sep = "\t", row.names = NULL)
n.sites <- sum(data.res$nb.sites)
n.obj <- sum(data.res$nb.obj)


base <- "https://github.com/zoometh/itineris/tree/main/"
inst.logo.root <- "https://raw.githubusercontent.com/zoometh/itineris/main/www/inst/"
```


```{r info-gen, echo = F}
df.info <- data.frame("Acronyme" = "Itineris",
                      "Code décision" = "AAPG2021",
                      "Titre" = "Italic metalwork TechnIques during the Early IroN AgE. Rethinking cultural InteractionS",
                      "Coordinateur" = "Veronica Cicolani",
                      "Affiliation" = "AOROC",
                      "Contact PGD" = "Thomas Huet",
                      "Version du PGD" = 1,
                      "Date" = format(Sys.time(), '%d %B %Y'),
                      stringsAsFactors = F
)
df.info.t <- t(df.info)
kable(df.info.t,"html",
      #  escape = F,
      # row.names = F,
      caption = "Informations générales") %>%
  # collapse_rows() %>%
  kable_styling(full_width = FALSE,
                position = "left",
                font_size = 10)
```

# Plan de gestion des données {#pgd}

Le plan de gestion des données (PGD, *data management plan*)  suivi par l'ANR Itineris est celui recommendé par le [COmité pour la Science Ouverte (CoSo)](https://www.ouvrirlascience.fr/the-committee-for-open-science/). Il est partagé par l'ensemble des [partenaires](#part) de l'ANR, s'appuie sur les services d'infrastructuration des données d'[Huma-Num](#humanum), *`r stri_rand_lipsum(1)`*

```{r dmp, echo=F, warning= F, fig.align='center', fig.height= 7, fig.width= 7, fig.cap="Plan de gestion des données du projet Itineris"}
dmp.logo.root <- "https://raw.githubusercontent.com/zoometh/itineris/main/www/dmp/"
dmg.steps <- c("Collecte et\nRéutilisation", 
               "Description",
               "Stockage",
               "Analyses",
               "Archivage",
               "Publication")
dmg.steps.url <- c("#wp3.step.collec",
                   "#wp3.step.describ",
                   "#wp3.bdweb",
                   "#wp3.step.anal",
                   "#wp3.step.archiv",
                   "#wp3.step.public")
dmg.steps.tit <- paste0("<a href='",dmg.steps.url,"'>",dmg.steps,"</a>")
name.im <- c(paste0(dmp.logo.root, "data_create.png"),
             paste0(dmp.logo.root, "data_tag.png"),
             paste0(dmp.logo.root, "data_store.png"),
             paste0(dmp.logo.root, "data_process.png"),
             paste0(dmp.logo.root, "data_archive.png"),
             paste0(dmp.logo.root, "data_publish.png"))
n.dmg.steps <- length(dmg.steps)
nodes <- data.frame(id=dmg.steps,
                    label = dmg.steps,
                    # label = paste0("[",dmg.steps,"](",dmg.steps.url,")"),
                    color = c(rep("#808080", n.dmg.steps)),
                    title = dmg.steps.tit,
                    font.size = rep(15, n.dmg.steps),
                    font.color = c(rep("black", n.dmg.steps)),
                    image = name.im,
                    shape = c(rep("image", n.dmg.steps)),
                    size = c(rep(24, n.dmg.steps)),
                    group = c(rep("dmp", n.dmg.steps))
)
a <- data.frame(from = dmg.steps[1:length(dmg.steps)-1],
                to = dmg.steps[2:length(dmg.steps)])
b <- data.frame(from = dmg.steps[length(dmg.steps)],
                to = dmg.steps[1])
edges <- rbind(a,b)
visNetwork(nodes, edges, 
           width = "600px", height = "600px") %>%
  visEdges(shadow = TRUE,
           smooth = TRUE,
           arrows =list(to = list(enabled = TRUE, 
                                  scaleFactor = 1)),
           color = list(color = "lightblue", highlight = "red"))
```



## Collecte et Réutilisation {#wp3.step.collec}

L'étude portera sur quelques <span style="color:darkgrey">`r n.obj`</span> objets en alliage de cuivre provenant de <span style="color:darkgrey">`r n.sites`</span> sites archéologiques. Parallèlement, une révision des corpus déjà publiés sera opérée. 

### Provenance

*`r stri_rand_lipsum(1)`*

### Données réutilisées

*`r stri_rand_lipsum(1)`*

### Données indédites

*`r stri_rand_lipsum(1)`*

### Volumes

*`r stri_rand_lipsum(1)`*


## Description {#wp3.step.describ}

Les données et métadonnées seront décrites selon les ISO-standards, des thésaurus (i.e., vocabulaires contrôlés, *shared vocabularies*) déjà existants et par de nouveaux thésaurus. Ci-dessous nous établissons une liste de référentiels possibles.


```{r isosdf, echo=F}
# isos.res <- read.table("C:/Users/supernova/Dropbox/My PC (supernova-pc)/Documents/itineris/data/isos_resume.tsv", sep = "\t", header = TRUE, fill = TRUE)
isos.res <- read.table(url.isos.res, header = T, sep = "\t", row.names = NULL)
kable(isos.res,"html",
      row.names = F,
      caption = "Iso-standards ou standards (ISO) utilisés") %>%
  collapse_rows() %>%
  kable_styling(full_width = FALSE,
                position = "center",
                font_size=12)
```

### Convention de nommage {#wp3.step.describ.name}

*`r stri_rand_lipsum(1)`*

## Stockage {#wp3.step.stock}

Le stockage des données se fera sur une base de données FileMaker (**WP3 T.5A**) consultable en ligne via un navigateur web (technologie WebDirect). Elle sera  hébergée sur les serveurs d’Huma-Num et référencée sur la grille Huma-Num. La Huma-Num héberge déjà de nombreux projets numériques développés par le laboratoire AOROC. Cette structure de données va permettre l'implémentation d'une saisie mult-utilisateurs, la pérennité du stockage et faciliter l'interfaçage avec des données de recherche déjà implémentées par la coordinatrice du projet (VC), le *gazetteer* [Archeolocalis](https://archeolocalis.chronocarto.eu/?zlang=fr), la base de données [BaseFer](https://basefer.chronocarto.eu/). 


## Analyses {#wp3.step.anal}

Les outils et les méthodes employées seront:

```{r methods-tools, echo = F}
tools.res <- read.table(url.tools.res, header = T, sep = "\t", row.names = NULL)
tools.res$WP <- str_replace(tools.res$WP, "WP1", "[WP1](#WP1)")
tools.res$WP <- str_replace(tools.res$WP, "WP2", "[WP2](#WP2)")
tools.res$WP <- str_replace(tools.res$WP, "WP3", "[WP3](#WP3)")
tools.res$output <- str_replace(tools.res$output, "geojson", "[geojson](#Fgeojson)")
tools.res$output <- str_replace(tools.res$output, ".json", "[.json](#Fjson)")
tools.res$output <- str_replace(tools.res$output, ".ply", "[.ply](#Fply)")
tools.res$output <- str_replace(tools.res$output, ".rdf", "[.rdf](#Frdf)")
tools.res$output <- str_replace(tools.res$output, ".shp", "[.shp](#Fshp)")
tools.res$output <- str_replace(tools.res$output, ".u3d", "[.u3d](#Fu3d)")
tools.res$output <- str_replace(tools.res$output, ".txt", "[.txt](#Fplaintext)")
tools.res$output <- str_replace(tools.res$output, ".csv", "[.csv](#Fplaintext)")
tools.res$output <- str_replace(tools.res$output, ".tsv", "[.tsv](#Fplaintext)")
tools.res$output <- str_replace(tools.res$output, ".u3d", "[.u3d](#Fu3d)")
tools.res$output <- str_replace(tools.res$output, ".x3d", "[.x3d](#Fx3d)")
tools.res$output <- str_replace(tools.res$output, ".wkt", "[.wkt](#Fplaintext)")
tools.res$output <- str_replace(tools.res$output, "plain text", "[plain text](#Fplaintext)")
tools.res$output <- str_replace(tools.res$output, "EXIF", "[EXIF](#MExif)")
tools.res$output <- str_replace(tools.res$output, "XMP", "[XMP](#MXmp)")
kable(tools.res,"html",
      row.names = F,
      caption = "Outils et méthodes") %>%
  collapse_rows() %>%
  kable_styling(full_width = FALSE,
                position = "center",
                font_size = 12)
```


## Archivage {#wp3.step.archiv}

L'archivage sur le temps long se fera avec le [CINES](https://www.huma-num.fr/les-services-par-etapes/#preservation) (v. [Infrastructure Huma-Num](#humanum))

## Publication {#wp3.step.public}

Le projet prévoit de publier: 

* du code informatique sous la forme de fonctions ou de *packages*
* des jeux de données (*datasets*)
* des documents de travail (*working papers*) avec du versionnage de DOI
* des documents de données (*data papers*)
* des articles scientifiques 

Ces documents et jeux de données seront seront référencés sur le site web du projet <span style='font-family: monospace;'><b>Itineris</b></span>, publiés sur des plateformes en libre accès (e.g. GitLab,  [OpenEdition](https://www.openedition.org/?lang=en)) et associés à des identifiants d'objets numériques (*digital object identifiers*, DOI) prenant en compte leur versionnage (*DOI versioning*) afin de garantir leur [FAIRisation](www.go-fair.org/fair-principles).

### Sérialisation {#wp3.step.describ.serial}

La base de données, accessible en ligne, est interopérable avec des procédures R (package  [RODBC](https://cran.r-project.org/web/packages/RODBC/index.html)) et Python ([pyodbc](https://pypi.org/project/pyodbc/)). Ces procédures facilitent l'intéropérabilité des données (*linked data*, LD) et le traitement de leur métadonnées. Celles-ci seront représentées préféretniellement avec JSON-LD, sous forme de graphes RDF. Les données décrites les données à partir de vocabulaires. L'historique des données sérailisée se fait avec VoID, DCAT ou PROV-O. Les données sérialisées sont trouvable avec SPARQL.

# Infrastructuration des données {#humanum}

L'infrastructure du TGIR [Huma-Num](https://www.huma-num.fr/) -- l'instance française de la *Digital Research Infrastructure for the Arts and Humanities* (DARIAH-EU) -- offre une grille de services facilitant l'inscription des projets de recherche dans le contexte de la Science ouverte. La cohérence de la gestion des données scientifiques du projet sera assurée par l'utilisation de ces services:

* développement intégré dans le conteneur d'application logicielles [GitLab](https://gitlab.huma-num.fr)
* échange des documents de travail (*working papers*, versionnage) sur le [ShareDocs](https://documentation.huma-num.fr/sharedocs-stockage/)
* etc.


```{r humanum, echo=F}
humanum.logo.root <- "https://raw.githubusercontent.com/zoometh/golasecca/main/LOD/www/humanum/"
isidore <- paste0(humanum.logo.root, "isidore.png")
traiter_ <- paste0(humanum.logo.root, "_traiter.png")
nakalona <- paste0(humanum.logo.root, "nakalona.png")
archiver_ <- paste0(humanum.logo.root, "cines.png")
stocker <- paste0(humanum.logo.root, "sharedocs.png")
service.fr <- c("Signaler",
                "Traiter",
                "Exposer",
                "Archiver",
                "Stocker")
service.url <- c("https://isidore.science/",
                 "https://www.huma-num.fr/les-services-par-etapes/#traitement",
                 "https://www.nakalona.fr/",
                 "https://www.huma-num.fr/les-services-par-etapes/#preservation",
                 "https://documentation.huma-num.fr/sharedocs-stockage/")
service <- c(paste0("[",service.fr,"](",service.url,")"))
service.logo <- c(paste0("![](",isidore," 'ISIDORE'){width=100px}"),
                  paste0("![](",traiter_," 'R, et autres'){width=100px}"),
                  paste0("![](",nakalona," 'NAKALONA'){width=100px}"),
                  paste0("![](",archiver_," 'CINES'){width=100px}"),
                  paste0("![](",stocker," 'ShareDocs'){width=100px}"))
df.humanum <- data.frame(service = service,
                         logo = service.logo,
                         stringsAsFactors = F)
kable(df.humanum,"html",
      row.names = F,
      caption = "Grille des services de la TGIR Huma-Num") %>%
  kable_styling(full_width = FALSE,
                position = "center",
                font_size=14)
```


# Membres du projet et Work packages {#part}

```{r calibrate, fig.height= 14, fig.width= 14, echo=FALSE, fig.align='center', fig.cap="Description des *Work packages* (WP), *task* (T.) et des acteurs institutionnels"}

# # View(dd)
mbr_nodes.res <- read.table(url.mbr_nodes.res, header = T, sep = "\t", row.names = NULL)
mbr_edges.res <- read.table(url.mbr_edges.res, header = T, sep = "\t", row.names = NULL)
visNetwork(mbr_nodes.res, mbr_edges.res, 
           width = "1000px", height = "1000px")
```


## Work packages

### WP1: Archaeometric analysis{#WP1}

*`r stri_rand_lipsum(1)`*

### WP2: Archaeological & Technological analysis{#WP2}

*`r stri_rand_lipsum(1)`*

### WP3: Data management & Computational archaeology{#WP3}

*`r stri_rand_lipsum(1)`*

# Lexique

## Métadonnées

### EXIF{#MExif}

Ce standard pour la description des métadonnées des photographies numériques est le plus largement utilisé. Il est intéropérable avec le langage R (package [exifr](https://cran.r-project.org/web/packages/exifr/index.html))

### XMP{#MXmp}

Standard pour la description des métadonnées des photographies numériques au format [.xml](#Fxml). Sérialisable ([RDF](#Frdf)/[.xml](#Fxml)), il supporte entièrement le [Dublin Core](https://www.iso.org/standard/71339.html). 

### INSPIRE{#MInspire}

Norme internationale pour les métadonnées spatiales (ISO [19139:2007](https://www.iso.org/standard/32557.html))

## Formats ouverts

### *plain text*{#Fplaintext}

Les formats *plain text* .txt, .csv et .tsv sont parmi les plus couramment utilisés pour les données alphanumériques. Le format .wkt est le standard d'écriture des données spatiales et géométriques.

### .geojson{#Fgeojson}

Dérivé de [.json](#Fjson), un objet .geojson peut être une géométrie, une entité ou une collection d'entités JavaScript.

### .json{#Fjson}

C'est LE format le plus courant pour écrire les graphes RDF. Le format .json est en train de remplacer [.xml](#Fxml) comme principal format d'échange de données (v. aussi [.geojson](#Fgeojson)).

### .ply{#Fply}

C'est le format privilégié pour l'enregistrement des données 3D, notamment pour le Web3D.

### .rdf{#Frdf}

Les triples RDF, ou graphes RDF, forment le standard et langage de base de description du web sémantique et du web de données. Il a été développé et adopté par le W3C pour l'échange des données.

### .shp{#Fshp}

Le format .shp est le standard pour les données vectorielles géoréférencées, utilisé par tous les SIG (v. (.wkt)[#Fplaintext]))

### .u3d{#Fu3d}

Format des données 3D qui peut être intégré dans un document LaTeX ou Acrobat.

### .x3d{#Fx3d}

Dans sa nouvelle norme HTML5, le consortium Web3D a mis au point une interface JavaScript qui permet de prendre en charge le format .x3d de manière native dans une page Web.

### .xml{#Fxml}

Syntaxe extensible créé pour faciliter l'échange automatisé de contenus complexes (arbres, texte enrichi). la syntaxe XML cpermet de définir différents espaces de noms (≠ HTML). C'est l'une des syntaxes possibles du RDF. Un fichier .xml peut être affiché en .css ou .xsl.


# Notes

Ce document [R](https://www.r-project.org/) + [Markdown](https://rmarkdown.rstudio.com/), déposé sur [GitHub](https://zoometh.github.io/itineris/), a été produit en open-source. 

# References



